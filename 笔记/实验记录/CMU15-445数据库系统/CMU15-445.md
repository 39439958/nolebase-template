# CMU15-445

## lec1 

数据库：定义、创建、查询、管理信息

数据模型：关系型、NoSQL（KV、Graph、Document文档、Column-family列族)、Array/Matrix

课程重点：**关系型数据库**

主键：primary key  uniquely identifies a single tuple

外键： 

DML：查询语言

关系代数：投影、join、笛卡尔积

关系代数仍然带有数据库的执行过程。

![image-20240307184333330](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240307184333330.png)



## lec3

1.静态表现

hardware page(保持读写原子性的最小单位)

os page

database page

![image-20240308091534189](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240308091534189.png)

2.动态调度 in lec5



## lec4

float value、large value

在不考虑HTAP的情况下（目前工业界HTAP的实践并不多），软件公司会将OLTP和OLAP这两类工作负载分开处理，用小数据库的集群处理OLTP，用分库分表的策略将工作负载分开，等到需要统计分析数据（即OLAP对应的场景）时，对这个集群执行ETL操作（提取数据->做变换->加载），把得到的数据转存到大的数据仓库里，然后让数据仓库应对OLAP的负载，这样将两种工作负载的处理分离开来的好处是，应对软件公司内部统计分析时的OLAP负载时，即便是执行复杂的SQL语句，也是在数据仓库上执行，不会影响集群，进而不会影响处理OLTP的效率以及用户体验，同时，小规模数据集群的架构也往往不适合运行复杂的SQL语句，可能光执行这些复杂的SQL就足以让它们挂掉，在数据仓库应对完OLAP的负载，即完成数据统计后，可以将统计后的结果写回小数据库集群，我们喜闻乐见的“用户年终总结”就是这么来的，刚刚说的这些概念形象一点的展示就是下图：

![image-20240308103720026](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240308103720026.png)



## lec 5 buffer poll

 类似与Cache对内存，TLB对页表，加一层缓存符合时空上



## lec6

开放地址哈希（线性探测）：往后探测，如果占了就继续探测，探测步长各有说法

ROBIN HOOD HASHING：冲突推移时尽量保证大家的偏移量比较均衡

CUCKOO HASHING：多个哈希换着插入不同的槽，冲突就占用别人的再给别人找。



chained hash：

![image-20240311204947516](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240311204947516.png)

JAVA MAP:数组+链表/红黑树

ExtendHash（pro1中已实现）、LinearHash

hash不适用与范围查询。



## lec7

B+树



## lec8

哈希表加锁：分段式哈希表 、按槽为粒度加锁（粒度更细）

Go中有一个并发哈希表并发实现策略是读写分离的。

CAS算法：先比较再设置，调用时设置原值和新值

B+树的并发操作：

1. 节点内部的数据需要并发
2. 节点之间的分裂和聚合操作需要并发



## lec9 排序与聚集

### 外部归并排序

 优化：提前拉取，多路归并   

归并的过程见王道数据结构笔记

- b+树中的聚簇和非聚簇即之前讲到的物化和非物化

### 聚集

利用排序做聚集

聚集优化



## lec10 连表

连接时的提前物化和推迟物化

join算法：

1. nested loop join（stupid）-> block nested loop join -> index nested loop join
2.  sort merge join 排序之后双指针查找
3. hash join 优化：在查询前做一个布隆过滤器

![image-20240319144158985](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240319144158985.png)

 

## lec11

火山模型

access method：sequential scan  , index scan，multi-index scan



## lec12

并行关心的内容：

- 吞吐量，时延

- 上层应用的响应性和可用性
- TCO 



查询间的并发（事务的并发控制）

查询内部的并发：并发算子的实现有两大思路：第一个思路是多个线程去操纵集中的全部数据（比如说多个线程同时读一个表），第二个思路是把集中的数据切开，把每部分分给相应的线程，使得线程可以在本地处理

Intra-query的三种实现：水平切分：每个线程做相同的事

![image-20240319171826985](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240319171826985.png)

垂直切分：一个线程负责执行一个阶段

![image-20240319171853075](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240319171853075.png)

Bushy parallelism：结合

![image-20240319171937980](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240319171937980.png)





分库分表

分库：将数据库分在不同盘上，我们可以把数据库实例中的不同Database分配到不同的硬盘当中，还可以在文件系统层面将不同的Database存入不同的文件夹中

分表：

- 垂直分：最后一个属性特别大时，分开，将热数据放在一个表，将低频数据放在另一个表
- 水平分：按照一些特殊谓词分



## lec13

优化器自动优化：

- 启发式：优化掉原本语句中低效的部分
- 基于代价：构建代价模型，选择代价最小的计划去执行



用户请求DBMS的过程：

![image-20240320102421031](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240320102421031.png)



关系代数的等价性保证了对查询优化的可靠性，例如谓词的下推，join算子的结合律、交换律

投影算子优化：

![image-20240320102826892](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240320102826892.png)



逻辑计划的优化：

- 连接在一块的谓词的分割
- 谓词的下推
- 笛卡尔积转join
- 投影下推



嵌套子查询的优化：子查询的解耦



表达式的重写



基于代价模型优化：

- 具体的物理代价：上图所列举的那些，这和硬件的性能有很大关系（一般数据库一体机的优化器会更多地考虑这类代价，因为数据库一体机的DBMS了解硬件的全部具体信息）
- 逻辑上的开销：给每个算子大致估算它的开销（比如说hash join算子/table reader每处理100个tuple会有多大开销），而且由于是估算，所以这和算子内部实际采取的算法是无关的。并且优化器还需要估计每个算子所处理的数据的量，这便需要一些数据的统计信息
- 比较细粒度地估计算子的开销：分析每个算子的内部实现有几步，根据采用的算法的时间复杂度去详细地估计算子的开销



## lec14

基于代价的优化器：依赖于DBMS内部的统计数据

select语句中相关基数的计算：谓词选择率等（基于独立事件概率模型）

不独立数据如何计算统计数据：使用等宽直方图，等深直方图，sampling-采样（如果表特别大的话，我们不妨从其中随机选择一些tuple然后构成一个小表，把这个小表作为完整表的一个代表，然后下一步转而分析这个小表，将得出的统计信息用于对完整表的查询代价分析）等。

通过以上各种策略估计出谓词的选择率。



计划列举：

- 单表查询：仅仅启发式地依据规则对逻辑计划rewrite，比如说确定访问数据的最佳方式（相关的规则可以是：“若存在这个字段的索引，那么就走索引”），而不用去量化分析查询计划的开销
- 夺标查询：暴力搜索所有可能结果

左深树带来了意想不到的好处：如果计划的执行模型（process model）是火山模型，那么就可以做到（假设B~D表的哈希表都做好了并且进行的是hash join）：A表和B表做join得到一个tuple，吐给上层的join算子，然后上层的join算子拿这个tuple和C表做join，之后再吐给上层，和D表做join，这便实现了几乎完美的流式操作，极大程度上使中间结果集更小

动态规划进行剪枝或数据量大时使用遗传算法迭代取较优值。



## lec15

并发控制和数据恢复

事务的ACID原则：

- atomicity 原子性：要么都成功执行，要么都没执行成功
- consistency 一致性：执行前后的状态一致，例如：a,b转账前后他们的总金额不变
- isolation 隔离性：事务之间不能相互看见
- Durability 持久性：事务提交之后永久存储，不能丢



### 原子性

一个事务的执行只会有两种结局，一是完成全部的内部操作之后执行commit，二是中途被abort，可以是客户端主动发出的中止，也可以被DBMS中止，这会形成回滚的效果，相当于事务还没开始执行。

实现原子性的方法：

- 日志作用：回滚、监控、性能考虑（延迟写回）

- Shadow Paging ：只备份修改过的



### 一致性

数据库中的所反映出的外部世界应该是逻辑上正确的，而且我们对数据库所执行的查询的结果也是逻辑上能讲的通的。

- 数据一致性
- Transaction Consistency，事务一致性：这是由业务去保证的，如果数据库在事务开始之前是一致的，那么在事务结束的时候也应该是一致的



### 隔离性

- 悲观协议：不要让问题发生，在问题出现之前就让线程停住

- 乐观协议：我们假设并发的冲突是少数的，只在问题出现之后再去回滚

  

如果一个执行调度能够和串行执行等价，那么它就拥有正确的一致性，它也被称作可串行化调度（Serializable Schedule）



- 读后写：不可重复读

- 写后读：脏读

- 写后写 ：脏写



### 持久性

事务的持久性要求事务提交的所有更改必须被写入存储介质持久化，并且不能有更新只进行一半的情况，也不能有事务失败之后更新被残留的情况

写前日志WAL之类的保证持久性。



## lec16

二阶段锁

严格二阶段锁

细粒度锁



## lec17

时间戳单调递增

时间戳方法：

- 系统时钟：系统时间会校准导致出问题
- 逻辑计数：简单的计数（在分布式系统中有可能有问题）
- Hybrid：结合两者



课程安排

1、基础时间戳方法

2、乐观控制方法

3、隔离级别



### BASIC T/O

每行记录赋予一个读时间戳和写时间戳

不能操作来自未来的数据

托马斯规则

 ![image-20240323200011484](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240323200011484.png)



幻读：读后插入一个新数据，读出来一个幻影

1. Re-Execute Scans
2. 谓词锁
3. 索引锁

mysql采用了间隙锁（类似于索引锁）



### 隔离级别

![image-20240323202520819](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240323202520819.png)

![image-20240323202609773](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240323202609773.png)

数据库设置隔离级别



数据库设置访问模式



## lec18 MVCC

2PL协议中，一个事务更新了一个对象之后，其他的事务就没有办法读这个对象了，直到这个事务提交。

而MVCC的基础思想是，留下数据的历史版本，这样其他的事务可以读历史版本而不是被阻塞。

DBMS一般使用事务的时间戳来决定版本号。

只依靠MVCC是不能达到调度的串行化的。

**并发控制手段/协议**

通常与前面所提及的并发控制协议结合起来使用。

**版本存储**

- 简单追加（Append-Only Storage）

- Time-Travel Storage

  ![image-20240325124909273](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240325124909273.png)

- 存储增量（Delta Storage）

  这样做就可以减少存储历史版本数据所需要的空间，相应的坏处就是，如果想查找历史版本的话，要通过增量存储段做恢复。这是一个用时间换空间的策略，MySQL采取的也是这个方法。

**垃圾回收**

什么样的版本需要垃圾回收？

- 版本太老
- 版本已经被回滚

怎么实现上面两个想法？

1. 以Tuple为单位回收

   - 后台清理：优化：维护一个dirty block bitmap，支持扫描上次GC之后被修改过的tuple
   - 合作清理：一边执行语句，一边清理，这样就不需要额外的GC线程

2. 以事务为单位回收

   - DBMS对每个事务会记下来它读/写了哪些东西，除此之外还会记录因为这个事务所进行的更新所导致的历史版本

   - 以事务为单位进行垃圾回收时，垃圾回收器不需要扫描一个个的tuple，而是只需要检查已经完成了的事务。

**索引管理**

1. 主键索引

在新的版本产生后，主键索引可能要更新它所指向的物理地址。如果想修改某个tuple的主键，那么就要完成一个先删除再插入的操作。

​	2.辅助索引

- logical pointers：Logical Pointers策略中索引的Value是逻辑地址，比如说主键/行id的值，这个策略的缺点是如果想拿到完整的tuple就需要再通过主索引找到相应的tuple
- physical pointers：	索引结构中最后记录的是物理地址，可以直接通过物理地址定位到完整的tuple，因此好处就是不用回表。缺点：加入了新版本之后，不止是要修改/维护主键索引里的指针，还要修改所有的辅助索引里的指针。
  - 与之相对的是，在Logical Pointers策略中，辅助索引最终只会指向相应的主键，然后再走主键索引，这样的话，在插入新版本之后只需要更新与维护主键索引里的指针，维护的开销大大降低
- 中间派：维护一个tuple id->物理地址的中间表，版本更新的时候只需更新中间表就可以了

## lec19 日志

#### 故障级别

- 事务级别的故障：逻辑错误（要求回滚或OCC时被迫回滚），内部状态错误（事务死锁）
- 系统级别的故障：软件故障（DBMS、OS），硬件故障（断电等，不包括硬盘故障）
- 存储介质的故障：（数据库开发者不必考虑）



#### 缓冲池策略

DBMS需要特定的缓存池管理方案来**实现如下的Undo/Redo操作**，从而保证事务的原子性和持久化。

- Undo: 消除不完整或中止的事务的影响的过程。

- Redo: 为了持久性，重新恢复提交的事务的效果的过程。



1. Steal and No-steal: Whether the DBMS allows an uncommitted txn to overwrite the most recent committed value of an object in non-volatile storage

2. Force and No-Force：如果DBMS要求事务在commit的时候必须把它所做的更新写入磁盘，这就对应的是Force策略，否则就是No-Force策略



**No-Steal+Force**：

No-Steal+Force这个策略的优点是它很容易实现，回滚时不需要做undo操作，因为被回滚的事务所做的更新没有被其他已经提交了的事务所连带着写入硬盘，只需把缓存池改回到原来的状态即可；重启恢复的时候也不需要做redo操作，因为事务commit的时候就已经完成了持久化

缺点：

- 刷盘操作过于频繁，性能不佳：每次commit的时候都会有硬盘I/O，导致用户也要随之等待；
- 事务在对数据库进行更新的过程中所读写过的所有东西在其提交之前都要一直暂存到缓存池里，否则如果有一部分被修改过的页提前被踢出缓存池，那么就破坏了事务的原子性。特别是全表扫描然后更新的这种场景下，缓存池就会非常紧张。也就是说，每个事务可修改的数据的量严重受缓存池大小限制（xv6的日志系统中也存在这样的问题）



**Shadow Paging**

Shadow Paging是上文No-Steal+Force策略的一个具体实现

Shadow Paging策略会造成对硬盘的大量的随机访问，这会降低性能，DBMS需要一个方案去把对磁盘的随机的写转换成连续的写，这就是下面要介绍的WAL（Write-Ahead Log）



**Write-Ahead Log 预写日志**

Steal+no-force策略

DBMS在把用户所修改过的缓存池中的页刷入磁盘之前，它需要先把预写日志写入磁盘中的日志文件，也就是说先完成预写日志的持久化，再完成缓存池里dirty page的持久化 



**Logging Schemes**

- 物理日志：记录每一个页具体到二进制级别的变化（e.g. 某个页的xxx偏移量位置处发生了xxx变化）
- 逻辑日志：记录事务所执行的操作，比如说事务所执行的SQL语句
- 混合日志



#### checkpoint





## lec20恢复

checkpoint 

**数据库恢复原型算法**



回放日志+回滚日志



LSN：日志序列号

- flushedLSN：最后落盘的那个 LSN，用于记录现在有哪些日志记录已经被刷入磁盘
- pageLSN：每一个数据页都有一个pageLSN，代表着对这个页进行最近一次修改的SQL语句对应的日志的LSN，也就是记录的是缓存当中这个页最新的修改
- recLSN：也是在数据页里面，用于记录自从这个页上次被刷入磁盘之后第一个修改这个页的SQL语句对应的日志的LSN，也就是记录的是缓存里面比磁盘上的页新的第一个版本，或者说是内存里面这个页最老的修改，pageLSN和recLSN是缓存里面对于这个页的修改的上限和下限
- lastLSN：用于记录到目前为止某个事务留下的最后一条日志的 LSN
- MasterRecord：上一次打的checkpoint点对应的LSN
- ![image-20240325153821380](C:\Users\xuliz\AppData\Roaming\Typora\typora-user-images\image-20240325153821380.png)

